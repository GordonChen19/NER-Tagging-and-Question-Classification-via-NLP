{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1. Sequence Tagging: NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vsCGGYu-JLkt",
    "outputId": "0277edf2-56ee-4678-a7d1-5eac9befe221"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vhncx65Ido0y",
    "outputId": "18df5ce1-f410-4801-c60a-95f518ab0816"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.3)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9OlIhoW4vrEz"
   },
   "outputs": [],
   "source": [
    "import gensim.downloader\n",
    "import os\n",
    "\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0UxIrzzxxCu-"
   },
   "outputs": [],
   "source": [
    "w2v = gensim.downloader.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pz9vnms5r75h",
    "outputId": "4e534f2a-a40c-4ade-fc08-3c643c16b445"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000000\n"
     ]
    }
   ],
   "source": [
    "print(len(w2v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qe580KAqz4f9"
   },
   "source": [
    "# Query the most similar vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j8egMwJi7q7V",
    "outputId": "4b680a22-4b03-49a7-fd76-37a1b0812c6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student:  students, 0.729\n",
      "Apple:  Apple_AAPL, 0.746\n",
      "apple:  apples, 0.720\n"
     ]
    }
   ],
   "source": [
    "words = [\"student\", \"Apple\", \"apple\"]\n",
    "\n",
    "for w in words:\n",
    "    most_sim_w, score = w2v.most_similar(positive= [w])[0]\n",
    "    print(f\"{w}:  {most_sim_w}, {score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2244o3tEF9rW"
   },
   "source": [
    "# Donwload dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "chBpBd-DGA5D",
    "outputId": "67931306-42e3-45cb-98af-737067fd5d19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wget in /usr/local/lib/python3.10/dist-packages (3.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y7NSvzgxHEso"
   },
   "outputs": [],
   "source": [
    "import wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JYGBOxg_HGTR",
    "outputId": "58db327e-d905-4c21-9092-03525fe3013f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eng.train already exists. Skipping\n",
      "eng.testa already exists. Skipping\n",
      "eng.testb already exists. Skipping\n"
     ]
    }
   ],
   "source": [
    "# Question 1.2 Download\n",
    "\n",
    "conll_raw_url = \"https://raw.githubusercontent.com/TheAnig/NER-LSTM-CNN-Pytorch/master/data/\"\n",
    "filenames = [\"eng.train\", \"eng.testa\", \"eng.testb\"]\n",
    "\n",
    "urls = {(f, f\"{conll_raw_url}/{f}\") for f in filenames}\n",
    "\n",
    "for fn, url in urls:\n",
    "    save_path = f\"/content/drive/MyDrive/NLPdataset/{fn}\"\n",
    "\n",
    "    if os.path.exists(save_path):\n",
    "        print(f\"{fn} already exists. Skipping\")\n",
    "        continue\n",
    "    wget.download(url, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a75ajFCmeRsM"
   },
   "source": [
    "# Partition Dataset into training, development and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3qmxfDnyJKrc",
    "outputId": "652b7e02-4fee-456d-b779-8481a682b644"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset (No. sentences): 14987\n",
      "developmentset (No. sentences): 3466\n",
      "testset (No. sentences): 3684\n",
      "tags in training set are ['I-ORG', 'O', 'I-MISC', 'I-PER', 'I-LOC', 'B-LOC', 'B-MISC', 'B-ORG']\n",
      "tags in development set are ['O', 'I-ORG', 'I-LOC', 'I-MISC', 'I-PER', 'B-MISC']\n",
      "tags in testing set are ['O', 'I-LOC', 'I-PER', 'I-MISC', 'I-ORG', 'B-ORG', 'B-MISC', 'B-LOC']\n",
      "complete set of tags: {'O', 'B-ORG', 'B-LOC', 'I-MISC', 'I-LOC', 'I-ORG', 'B-MISC', 'I-PER'}\n"
     ]
    }
   ],
   "source": [
    "# File has one line\n",
    "\n",
    "# First column is the word\n",
    "# Second is POS tag\n",
    "# Third is Consistuency parsing tag\n",
    "# Fourth is NER tag\n",
    "\n",
    "# The NER tagging column\n",
    "\n",
    "\n",
    "root = '/content/drive/MyDrive/NLPdataset/'\n",
    "\n",
    "# Returns a 3 dim array of sentences x words x (word_value, word_category)\n",
    "def process_sets(filepath):\n",
    "    raw = open(filepath)\n",
    "    fin, curr = [], []\n",
    "    tags = []\n",
    "\n",
    "    for r in raw:\n",
    "        if r == \"\\n\":\n",
    "            fin.append(curr)\n",
    "            curr = []\n",
    "            continue\n",
    "        elif 'DOCSTART' in r:# Some files have these which are used to divide sentences\n",
    "          continue\n",
    "        else:\n",
    "          r = r[:-1].split()\n",
    "\n",
    "        if(len(r)!=4):\n",
    "          print(r)\n",
    "        curr.append([r[0],r[3]]) #Extract first and last column (NER Tag)\n",
    "        if r[3] not in tags:\n",
    "          tags.append(r[3])\n",
    "\n",
    "\n",
    "    fin.append(curr)\n",
    "    return fin,tags\n",
    "\n",
    "trainset,traintags = process_sets(root+ \"eng.train\")\n",
    "devset, devtags= process_sets(root +\"eng.testa\")   # aka validation set\n",
    "testset, testtags = process_sets(root +\"eng.testb\")\n",
    "\n",
    "print (f'trainset (No. sentences): {len(trainset)}')\n",
    "print (f'developmentset (No. sentences): {len(devset)}')\n",
    "print (f'testset (No. sentences): {len(testset)}')\n",
    "\n",
    "print(f'tags in training set are {traintags}')\n",
    "print(f'tags in development set are {devtags}')\n",
    "print(f'tags in testing set are {testtags}')\n",
    "print(f'complete set of tags: {set(traintags+devtags+testtags)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YbqvO-KcfF2H"
   },
   "source": [
    "# Example sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nO-ov1NI2kg_"
   },
   "outputs": [],
   "source": [
    "def joinString(entity, joinentity):\n",
    "    if(entity==\"\"):\n",
    "        return joinentity\n",
    "    elif(joinentity[0]==\"'\"):\n",
    "        return entity + joinentity\n",
    "\n",
    "    else:\n",
    "        return entity + \" \" + joinentity\n",
    "\n",
    "\n",
    "def getSentence():\n",
    "    for sentence in trainset:\n",
    "        named_entities = []\n",
    "        previous_word = ''\n",
    "        counter = 0 #Number of entities with more than one word\n",
    "        current_tag = None #B,I,O\n",
    "        entity_tag = None #e.g. PER, LOC, MISC\n",
    "        word_length = 0\n",
    "        for i,word in enumerate(sentence):\n",
    "            if word[1]=='O': #If this is not an entity\n",
    "                current_tag=None\n",
    "                if word_length>1:\n",
    "                    counter+=1\n",
    "                if previous_word!='':\n",
    "                    named_entities.append(previous_word)\n",
    "                previous_word=''\n",
    "                word_length=0\n",
    "            else:\n",
    "                if current_tag is None: #If the current named entity succeeds a 'O' or is the first word of the sentence\n",
    "                    current_tag,entity_tag = word[1].split('-')\n",
    "                    previous_word=joinString(previous_word,word[0])\n",
    "                    word_length=1\n",
    "\n",
    "                else:\n",
    "                    tmp_tag,tmp_type = word[1].split('-')\n",
    "                    if tmp_tag == 'B' or tmp_type!=entity_tag: #Beginning of a new named entity\n",
    "                        if word_length>1:\n",
    "                            counter+=1\n",
    "                        named_entities.append(previous_word)\n",
    "                        previous_word=''\n",
    "                        word_length=0\n",
    "                        current_tag,entitiy_tag=word[1].split('-')\n",
    "                    else: #Continuation of the previous entity\n",
    "                        previous_word=joinString(previous_word,word[0])\n",
    "                        current_tag=tmp_tag\n",
    "                        word_length+=1\n",
    "\n",
    "                    if i == len(sentence)-1 and previous_word!='':\n",
    "                        if(word_length>1):\n",
    "                            counter+=1\n",
    "                        named_entities.append(previous_word)\n",
    "\n",
    "        if counter>2:\n",
    "            return named_entities,sentence\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yK6zrjsbg_lb",
    "outputId": "3155ad87-4f13-47b1-d2d4-ea4d62346bef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Germany', \"Welsh National Farmers' Union\", 'NFU', 'John Lloyd Jones', 'BBC radio']\n",
      "\" What we have to be extremely careful of is how other countries are going to take Germany's lead , \" Welsh National Farmers' Union ( NFU ) chairman John Lloyd Jones said on BBC radio .\n",
      "[['\"', 'O'], ['What', 'O'], ['we', 'O'], ['have', 'O'], ['to', 'O'], ['be', 'O'], ['extremely', 'O'], ['careful', 'O'], ['of', 'O'], ['is', 'O'], ['how', 'O'], ['other', 'O'], ['countries', 'O'], ['are', 'O'], ['going', 'O'], ['to', 'O'], ['take', 'O'], ['Germany', 'I-LOC'], [\"'s\", 'O'], ['lead', 'O'], [',', 'O'], ['\"', 'O'], ['Welsh', 'I-ORG'], ['National', 'I-ORG'], ['Farmers', 'I-ORG'], [\"'\", 'I-ORG'], ['Union', 'I-ORG'], ['(', 'O'], ['NFU', 'I-ORG'], [')', 'O'], ['chairman', 'O'], ['John', 'I-PER'], ['Lloyd', 'I-PER'], ['Jones', 'I-PER'], ['said', 'O'], ['on', 'O'], ['BBC', 'I-ORG'], ['radio', 'I-ORG'], ['.', 'O']]\n"
     ]
    }
   ],
   "source": [
    "entities, sentence_tags = getSentence()\n",
    "\n",
    "sentenceString = \"\"\n",
    "for word in sentence_tags:\n",
    "    sentenceString=joinString(sentenceString,word[0])\n",
    "\n",
    "print(entities)\n",
    "print(sentenceString)\n",
    "print(sentence_tags)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kmWItuCWYDWF"
   },
   "source": [
    "# Out of vocabulary word preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QH51CeCQbYae"
   },
   "outputs": [],
   "source": [
    "# function to get all words not in the word2vec model\n",
    "def get_words_not_in_model(set, w2v):\n",
    "    abs_w2v = [] # array to store words that are not in the word2vec model\n",
    "    abs_w2v_lower = [] # array to store words that are not in the word2vec model, but are in lower case\n",
    "    for sentences in set:\n",
    "        for word, type in sentences:\n",
    "            if word not in w2v.key_to_index:\n",
    "                #print(word)\n",
    "                abs_w2v.append(word)\n",
    "                if word.lower() not in w2v.key_to_index:\n",
    "                    abs_w2v_lower.append(word.lower())\n",
    "    return abs_w2v, abs_w2v_lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8_QvwFbfbcr5"
   },
   "outputs": [],
   "source": [
    "\n",
    "# function to remove words that are puncutation, numbers, or special characters\n",
    "def remove_punc_num_special(s):\n",
    "    clean_set = []\n",
    "    for sentence in s:\n",
    "        clean_sentence = []\n",
    "        for word, tag in sentence:\n",
    "            if any(c.isalpha() for c in word):\n",
    "                clean_sentence.append([word, tag])\n",
    "        clean_set.append(clean_sentence)\n",
    "    return clean_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uynylU3_mn1L"
   },
   "outputs": [],
   "source": [
    "def word_stemming(s,w2v):\n",
    "    ps = PorterStemmer()\n",
    "    stemmed_sentences=[]\n",
    "    for sentence in s:\n",
    "        stemmed_sentence=[]\n",
    "        for word, tag in sentence:\n",
    "            if (word not in w2v.key_to_index and  ps.stem(word) in w2v.key_to_index):\n",
    "                stemmed_sentence.append([ps.stem(word),tag])\n",
    "            else:\n",
    "                stemmed_sentence.append([word,tag])\n",
    "        stemmed_sentences.append(stemmed_sentence)\n",
    "    return stemmed_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dd7zWWCEtNrd"
   },
   "outputs": [],
   "source": [
    "def remove_stop_words(s): #Try subword embedding first\n",
    "    stop_words=['of','a','and','to',\"'s\"]\n",
    "    stopless_sentences=[]\n",
    "    for sentence in s:\n",
    "        stopless_sentence=[]\n",
    "        for word,tag in sentence:\n",
    "            if word not in stop_words:\n",
    "                stopless_sentence.append([word,tag])\n",
    "\n",
    "        stopless_sentences.append(stopless_sentence)\n",
    "    return stopless_sentences\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_tOrD3Crq60i"
   },
   "outputs": [],
   "source": [
    "def hyphen_seperation(s,w2v):\n",
    "    seperated_sentences=[]\n",
    "    for sentence in s:\n",
    "        seperated_sentence=[]\n",
    "        for word,tag in sentence:\n",
    "            array_of_words = word.split('-')\n",
    "            for individual_word in array_of_words:\n",
    "                seperated_sentence.append([individual_word,tag])\n",
    "        seperated_sentences.append(seperated_sentence)\n",
    "    return seperated_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QU04NuJbctPA",
    "outputId": "da9e06aa-6042-41e1-d273-570777fa3b1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83402 83322\n"
     ]
    }
   ],
   "source": [
    "# check number of words not in word2vec model\n",
    "fullset = trainset + devset + testset\n",
    "abs_w2v, abs_w2v_lower = get_words_not_in_model(fullset, w2v)\n",
    "print(len(abs_w2v), len(abs_w2v_lower))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w8K37mrRO4l3"
   },
   "source": [
    "# Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D-iubbQhO68G"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1XuOB4rLEAyV"
   },
   "outputs": [],
   "source": [
    "# takes in a set of sentences in the form of a list of lists of tuples, and\n",
    "# returns a list of list of words and tags\n",
    "def separate_words_tags(set):\n",
    "    sentences = []\n",
    "    labels = []\n",
    "\n",
    "    for sentence in set:\n",
    "        current_sentence = []\n",
    "        current_label = []\n",
    "        for word, tag in sentence:\n",
    "            current_sentence.append(word)\n",
    "            current_label.append(tag)\n",
    "        sentences.append(current_sentence)\n",
    "        labels.append(current_label)\n",
    "    return sentences, labels\n",
    "\n",
    "# class to create a dataset for the NER task\n",
    "class NERDataset(Dataset):\n",
    "    def __init__(self, sentences, labels, word_to_ix, tag_to_ix):\n",
    "        self.sentences = sentences\n",
    "        self.labels = labels\n",
    "        self.word_to_ix = word_to_ix\n",
    "        self.tag_to_ix = tag_to_ix\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sentence = self.sentences[index]\n",
    "        label = self.labels[index]\n",
    "        original_length = len(sentence)\n",
    "\n",
    "        sentence = [self.word_to_ix.get(word, 3000000) for word in sentence] # 3000000 is the index for <UNK>\n",
    "        label = [self.tag_to_ix[tag] for tag in label]\n",
    "\n",
    "        return torch.tensor(sentence, dtype=torch.long), torch.tensor(label, dtype=torch.long), original_length\n",
    "\n",
    "\n",
    "# function to pad the sequences in a batch\n",
    "def pad_collate(batch):\n",
    "    (xx, yy, lens) = zip(*batch)  # unzip the batch\n",
    "\n",
    "    x_lens = [len(x) for x in xx]  # get lengths of sequences\n",
    "    y_lens = [len(y) for y in yy]  # get lengths of labels\n",
    "\n",
    "    max_x_len = max(x_lens)\n",
    "    max_y_len = max(y_lens)\n",
    "\n",
    "    xx_pad = torch.full((len(xx), max_x_len), 3000000, dtype=torch.long)  # create a matrix filled with 3000000\n",
    "    yy_pad = torch.zeros(len(yy), max_y_len, dtype=torch.long)  # create a matrix of zeros with correct dimensions\n",
    "\n",
    "    for i, (x, y) in enumerate(zip(xx, yy)):\n",
    "        xx_pad[i, :x_lens[i]] = x\n",
    "        yy_pad[i, :y_lens[i]] = y\n",
    "\n",
    "    return xx_pad, yy_pad, lens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "87C0jiowmJVE",
    "outputId": "0e928d7d-94a3-4b5f-efa5-2dd440781bc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3698 3672\n",
      "2529 2513\n",
      "604 599\n",
      "565 560\n"
     ]
    }
   ],
   "source": [
    "# clean dataset by removing meaningless words\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "fullset = remove_punc_num_special(fullset) #Remove punctuation, special characters and numbers\n",
    "fullset = hyphen_seperation(fullset,w2v) #Address hyphen separated words\n",
    "fullset = word_stemming(fullset,w2v) #Porter Stemmer\n",
    "fullset = remove_stop_words(fullset) #Remove stop words\n",
    "abs_w2v, abs_w2v_lower = get_words_not_in_model(fullset, w2v)\n",
    "print(len(abs_w2v), len(abs_w2v_lower))\n",
    "\n",
    "#Trainset Transformation\n",
    "trainset = remove_punc_num_special(trainset) #Remove punctuation, special characters and numbers\n",
    "trainset = hyphen_seperation(trainset,w2v) #Address hyphen separated words\n",
    "trainset = word_stemming(trainset,w2v) #Porter Stemmer\n",
    "trainset = remove_stop_words(trainset) #Remove stop words\n",
    "abs_w2v, abs_w2v_lower = get_words_not_in_model(trainset, w2v)\n",
    "print(len(abs_w2v), len(abs_w2v_lower))\n",
    "\n",
    "#Validation set transformation\n",
    "devset = remove_punc_num_special(devset) #Remove punctuation, special characters and numbers\n",
    "devset = hyphen_seperation(devset,w2v) #Address hyphen separated words\n",
    "devset = word_stemming(devset,w2v) #Porter Stemmer\n",
    "devset = remove_stop_words(devset) #Remove stop words\n",
    "abs_w2v, abs_w2v_lower = get_words_not_in_model(devset, w2v)\n",
    "print(len(abs_w2v), len(abs_w2v_lower))\n",
    "\n",
    "#Test set transformation\n",
    "testset = remove_punc_num_special(testset) #Remove punctuation, special characters and numbers\n",
    "testset = hyphen_seperation(testset,w2v) #Address hyphen separated words\n",
    "testset = word_stemming(testset,w2v) #Porter Stemmer\n",
    "testset = remove_stop_words(testset) #Remove stop words\n",
    "abs_w2v, abs_w2v_lower = get_words_not_in_model(testset, w2v)\n",
    "print(len(abs_w2v), len(abs_w2v_lower))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HS065tylI-VC"
   },
   "source": [
    "# Map all words to embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OAeEsfWsY_qO",
    "outputId": "1cb9bf34-7754-4a88-ca87-e810fe46c769"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000000\n"
     ]
    }
   ],
   "source": [
    "w2v_size = len(w2v)\n",
    "print(w2v_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "idpxpZxJYvH3"
   },
   "outputs": [],
   "source": [
    "w2v_size = len(w2v)\n",
    "\n",
    "w2v['<UNK>']=np.zeros(300)\n",
    "\n",
    "\n",
    "\n",
    "word_to_ix = {\"<PAD>\":w2v_size,\"<UNK>\":w2v_size}\n",
    "tag_to_ix = {\"<PAD>\": 0, \"O\": 1, \"B-MISC\": 2, \"B-LOC\": 3, \"I-MISC\": 4, \"I-LOC\": 5, \"B-ORG\": 6, \"I-PER\": 7, \"I-ORG\": 8}\n",
    "\n",
    "#Map each word to a metric embedding\n",
    "for sentence in fullset:\n",
    "    for word,tag in sentence:\n",
    "        if word in w2v.key_to_index:\n",
    "            word_to_ix[word]=w2v.key_to_index[word]\n",
    "        elif word.lower() in w2v.key_to_index:\n",
    "            word_to_ix[word]=w2v.key_to_index[word.lower()]\n",
    "        else:\n",
    "            word_to_ix[word]=w2v.key_to_index['<UNK>']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XowOgC3dMU7f"
   },
   "outputs": [],
   "source": [
    "sentences, labels = separate_words_tags(trainset) # separate words and tags\n",
    "train_data = NERDataset(sentences, labels, word_to_ix, tag_to_ix)\n",
    "\n",
    "sentences, labels = separate_words_tags(devset)\n",
    "dev_data = NERDataset(sentences, labels, word_to_ix, tag_to_ix)\n",
    "\n",
    "sentences, labels = separate_words_tags(testset)\n",
    "test_data = NERDataset(sentences, labels, word_to_ix, tag_to_ix)\n",
    "\n",
    "# Creating DataLoader ; pad_collate function pads sentences to the length of the longest sentence in the batch\n",
    "batch_size = 16\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, collate_fn=pad_collate)\n",
    "dev_loader = DataLoader(dev_data, batch_size=batch_size, shuffle=True, collate_fn=pad_collate)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, collate_fn=pad_collate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5J96jCHip-pD"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "poTFRhXbfLKd"
   },
   "source": [
    "# Long Short Term Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZqMIgIg1j1g2"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import string\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "amY4ufLSMjD-",
    "outputId": "e5b054c8-d526-4113-ce2a-8139eba99502"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seqeval in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.23.5)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.2.2)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.11.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install seqeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ty4Sa14eHZqC"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# early stopping obtained from tutorial\n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience=3, min_delta=0):\n",
    "        self.patience = patience # how many epochs to wait before stopping when loss is no longer decreasing\n",
    "        self.min_delta = min_delta # minimum difference between new loss and old loss to be considered as a decrease in loss\n",
    "        self.counter = 0 # number of epochs since loss was last decreased\n",
    "        self.min_validation_loss = np.inf # minimum validation loss achieved so far\n",
    "\n",
    "    def early_stop(self, validation_loss):\n",
    "        if validation_loss < self.min_validation_loss: # new loss is lower than old loss\n",
    "            self.min_validation_loss = validation_loss # update minimum loss\n",
    "            self.counter = 0 # reset counter\n",
    "        elif validation_loss > (self.min_validation_loss + self.min_delta): # new loss is higher than old loss + minimum difference\n",
    "            self.counter += 1 # increase counter\n",
    "            if self.counter >= self.patience:\n",
    "                return True # stop training\n",
    "        return False # continue training\n",
    "\n",
    "\n",
    "# set random seed\n",
    "def set_seed(seed = 0):\n",
    "    '''\n",
    "    set random seed\n",
    "    '''\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "# Train step\n",
    "def train_step(model, trainloader, optimizer, device, lossfn):\n",
    "    model.train()  # set model to training mode\n",
    "    total_loss = 0.0\n",
    "\n",
    "    # Iterate over the training data\n",
    "    for i, data in trainloader:\n",
    "        inputs, labels, _ = data  # get the inputs and labels\n",
    "        inputs, labels = inputs.to(device), labels.to(device)  # move them to the device\n",
    "\n",
    "        optimizer.zero_grad()  # zero the gradients\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = lossfn(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimisation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()  # accumulate the loss\n",
    "        trainloader.set_postfix({'Training loss': '{:.4f}'.format(total_loss/(i+1))})  # Update the progress bar with the training loss\n",
    "\n",
    "    train_loss = total_loss / len(trainloader)\n",
    "    return train_loss\n",
    "\n",
    "\n",
    "\n",
    "# Test step\n",
    "def val_step(model, valloader, lossfn, device):\n",
    "    from seqeval.metrics import f1_score\n",
    "    idx_to_tag = {1:\"O\",2: \"B-MISC\",3: \"B-LOC\",4: \"I-MISC\",5: \"I-LOC\",6: \"B-ORG\",7: \"I-PER\",8: \"I-ORG\"}\n",
    "    model.eval() # set model to evaluation mode\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total_words = 0\n",
    "    all_batch_preds = []  # List to store batch predictions\n",
    "    all_batch_labels = []  # List to store batch labels\n",
    "\n",
    "    with torch.no_grad(): # disable gradient calculation\n",
    "        for data in valloader:\n",
    "            inputs, labels, lens = data # get the inputs and labels and actual lengths\n",
    "            inputs, labels = inputs.to(device), labels.to(device) # move them to the device\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = lossfn(outputs, labels)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Get the index of the max log-probability along the tagset_size dimension\n",
    "            _, predicted = torch.max(outputs.permute(0, 2, 1), 2)\n",
    "\n",
    "            batch_preds = []\n",
    "            batch_labels = []\n",
    "\n",
    "            batch_preds_acc = []\n",
    "            batch_labels_acc = []\n",
    "\n",
    "            for i in range(len(lens)):\n",
    "                batch_preds.append([idx_to_tag[int(word)] for word in predicted[i, :lens[i]]])  # Append predictions but only up to the actual length of the sentence\n",
    "                batch_labels.append([idx_to_tag[int(word)] for word in labels[i, :lens[i]]])\n",
    "\n",
    "                batch_preds_acc.extend(predicted[i, :lens[i]].cpu().numpy())  # Append predictions but only up to the actual length of the sentence\n",
    "                batch_labels_acc.extend(labels[i, :lens[i]].cpu().numpy())\n",
    "\n",
    "            correct += sum(p == l for p, l in zip(batch_preds_acc, batch_labels_acc))  # Accumulate correct predictions for this batch\n",
    "            total_words += sum(lens)  # Accumulate the actual sentence lengths for this batch\n",
    "\n",
    "            all_batch_preds.extend(batch_preds)  # Append batch predictions to the list\n",
    "            all_batch_labels.extend(batch_labels)  # Append batch labels to the list\n",
    "\n",
    "    val_loss = total_loss / len(valloader)\n",
    "    accuracy = 100 * correct / total_words\n",
    "    f1 = f1_score(all_batch_labels, all_batch_preds,average='macro')\n",
    "\n",
    "    return val_loss, accuracy, f1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Save model\n",
    "def save_model(model, path):\n",
    "    torch.save(model.state_dict(), path)\n",
    "\n",
    "\n",
    "# Training loop\n",
    "def train(model, tl, vl, opt, loss, device, epochs, early_stopper, path):\n",
    "    train_loss_list = []\n",
    "    val_loss_list = []\n",
    "    val_acc_list = []\n",
    "    f1_list = []\n",
    "\n",
    "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "        start_time = time.time()  # Record the start time of the epoch\n",
    "\n",
    "        # Wrap the trainloader with tqdm for the progress bar\n",
    "        pbar = tqdm(enumerate(tl), total=len(tl), desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "\n",
    "        train_loss = train_step(model, pbar, opt, device, loss)  # Pass the tqdm-wrapped loader\n",
    "        val_loss,val_acc, F1 = val_step(model, vl, loss, device)\n",
    "\n",
    "        train_loss_list.append(train_loss)\n",
    "        val_loss_list.append(val_loss)\n",
    "        val_acc_list.append(val_acc)\n",
    "        f1_list.append(F1)\n",
    "\n",
    "        # Print time taken for epoch\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{epochs} took {elapsed_time:.2f}s | Train loss: {train_loss:.4f} | Val loss: {val_loss:.4f} | Val accuracy: {val_acc:.2f}% | F1: {F1:.4f} | EarlyStopper count: {early_stopper.counter}')\n",
    "\n",
    "        # save as last_model after every epoch\n",
    "        save_model(model, os.path.join(path, 'last_model.pt'))\n",
    "\n",
    "        # save as best_model if validation loss is lower than previous best validation loss\n",
    "        if val_loss < early_stopper.min_validation_loss:\n",
    "            save_model(model, os.path.join(path, 'best_model.pt'))\n",
    "\n",
    "        if early_stopper.early_stop(val_loss):\n",
    "            print('Early stopping')\n",
    "            break\n",
    "\n",
    "    return train_loss_list, val_loss_list, val_acc_list, f1_list\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# word_embeddings = nn.Embedding.from_pretrained(torch.FloatTensor(w2v.vectors), freeze=False)\n",
    "# word_embeddings(torch.LongTensor([w2v.key_to_index['<UNK>']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NSqmeMrfHu63"
   },
   "source": [
    "# Defining Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9PZCf7IwHwq2"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# LSTM Model\n",
    "class NERModel(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size, weights_matrix=None, freeze_weights=True):\n",
    "        super(NERModel, self).__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        if weights_matrix is not None:\n",
    "            self.word_embeddings = nn.Embedding.from_pretrained(weights_matrix, freeze=freeze_weights)\n",
    "            # initialize word embeddings with pretrained weights and freeze them\n",
    "        else:\n",
    "            self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True,bidirectional=True)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
    "        # Linear layer maps from hidden state space to tag space\n",
    "\n",
    "\n",
    "    def forward(self, sentences):\n",
    "        '''\n",
    "        sentences: batch_size x max_seq_length\n",
    "        tag_space: batch_size x tagset_size x max_seq_length\n",
    "        '''\n",
    "        embeds = self.word_embeddings(sentences) # Embed the input sentence\n",
    "\n",
    "        # LSTM input shape: batch_size x max_seq_length x embedding_dim\n",
    "        lstm_out, _ = self.lstm(embeds)\n",
    "\n",
    "        # LSTM output shape: batch_size x max_seq_length x hidden_dim\n",
    "        # reshape it for the linear layer\n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
    "        # shape: (batch_size * max_seq_length) x hidden_dim\n",
    "\n",
    "        lstm_out=self.dropout(lstm_out)\n",
    "\n",
    "        tag_space = self.hidden2tag(lstm_out)\n",
    "\n",
    "        # reshape back to batch_size x max_seq_length x tagset_size\n",
    "        tag_space = tag_space.contiguous().view(sentences.shape[0], sentences.shape[1], -1)\n",
    "\n",
    "        # swap dimensions to make it batch_size x tagset_size x max_seq_length\n",
    "        tag_space = tag_space.permute(0, 2, 1)\n",
    "\n",
    "        return tag_space # Return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YFjKEQB5Fa78"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "81K1SYvRFcE5"
   },
   "outputs": [],
   "source": [
    "embedding_dim = 300\n",
    "hidden_dim = 1024\n",
    "vocab_size = len(word_to_ix)\n",
    "tagset_size = len(tag_to_ix)\n",
    "weights_matrix = torch.FloatTensor(w2v.vectors)\n",
    "\n",
    "\n",
    "model = NERModel(embedding_dim=embedding_dim, hidden_dim=hidden_dim, vocab_size=vocab_size, tagset_size=tagset_size, weights_matrix=weights_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZcnUbsqKG6mW"
   },
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "loss = torch.nn.CrossEntropyLoss(ignore_index=0 )\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "epochs = 5 # number of epochs\n",
    "early_stopper = EarlyStopper(patience=2) # initialise early stopper\n",
    "\n",
    "# Make directory to save baseline model\n",
    "model_path = \"../saved_models/\"\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "\n",
    "# Define the device-specific path\n",
    "device_type = None\n",
    "if device == torch.device(\"cuda\"):\n",
    "    device_type = \"cuda\"\n",
    "elif device == torch.device(\"mps\"):\n",
    "    device_type = \"mps\"\n",
    "else:\n",
    "    device_type = \"cpu\"\n",
    "\n",
    "# Construct the full path\n",
    "device_path = os.path.join(model_path, device_type)\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(device_path):\n",
    "    os.mkdir(device_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TaB47BRJJsjw",
    "outputId": "f851eacd-0345-4587-874d-807763b156b5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 937/937 [00:10<00:00, 88.04it/s, Training loss=0.2480]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 took 13.13s | Train loss: 0.2480 | Val loss: 0.1391 | Val accuracy: 95.52% | F1: 0.7267 | EarlyStopper count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 937/937 [00:10<00:00, 88.33it/s, Training loss=0.1304]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 took 12.99s | Train loss: 0.1304 | Val loss: 0.1237 | Val accuracy: 96.14% | F1: 0.7661 | EarlyStopper count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 937/937 [00:10<00:00, 89.40it/s, Training loss=0.1087]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 took 12.83s | Train loss: 0.1087 | Val loss: 0.1222 | Val accuracy: 96.23% | F1: 0.7726 | EarlyStopper count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 937/937 [00:10<00:00, 88.87it/s, Training loss=0.0903]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 took 12.98s | Train loss: 0.0903 | Val loss: 0.1100 | Val accuracy: 96.61% | F1: 0.7968 | EarlyStopper count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 937/937 [00:10<00:00, 88.35it/s, Training loss=0.0784]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 took 12.98s | Train loss: 0.0784 | Val loss: 0.1089 | Val accuracy: 96.68% | F1: 0.7939 | EarlyStopper count: 0\n"
     ]
    }
   ],
   "source": [
    "train_loss_list, val_loss_list, val_acc_list, f1_list = train(model, train_loader, dev_loader, optimiser, loss, device, epochs, early_stopper, device_path) # train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "dVS3i_7rJsoT",
    "outputId": "461489cc-f3dc-45e6-8ea0-f016b18828e8"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epoch_range = [i for i in range(1,epochs+1)]\n",
    "# plot training and validation loss, and f1 score\n",
    "plt.plot(epoch_range,train_loss_list, label='Training loss')\n",
    "plt.plot(epoch_range,val_loss_list, label='Validation loss')\n",
    "plt.plot(epoch_range,f1_list, label='F1 score')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PrswPMJts89a"
   },
   "outputs": [],
   "source": [
    "# Test step\n",
    "\n",
    "\n",
    "from seqeval.metrics import f1_score\n",
    "idx_to_tag = {\n",
    "1:\"O\",\n",
    "2: \"B-MISC\",\n",
    "3: \"B-LOC\",\n",
    "4: \"I-MISC\",\n",
    "5: \"I-LOC\",\n",
    "6: \"B-ORG\",\n",
    "7: \"I-PER\",\n",
    "8: \"I-ORG\"\n",
    "}\n",
    "model.eval() # set model to evaluation mode\n",
    "correct = 0\n",
    "total_words = 0\n",
    "all_batch_preds = []  # List to store batch predictions\n",
    "all_batch_labels = []  # List to store batch labels\n",
    "\n",
    "with torch.no_grad(): # disable gradient calculation\n",
    "    for data in test_loader:\n",
    "        inputs, labels, lens = data # get the inputs and labels and actual lengths\n",
    "        inputs, labels = inputs.to(device), labels.to(device) # move them to the device\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Get the index of the max log-probability along the tagset_size dimension\n",
    "        _, predicted = torch.max(outputs.permute(0, 2, 1), 2)\n",
    "\n",
    "        batch_preds = []\n",
    "        batch_labels = []\n",
    "\n",
    "        batch_preds_acc = []\n",
    "        batch_labels_acc = []\n",
    "\n",
    "        for i in range(len(lens)):\n",
    "            batch_preds.append([idx_to_tag[int(word)] for word in predicted[i, :lens[i]]])  # Append predictions but only up to the actual length of the sentence\n",
    "            batch_labels.append([idx_to_tag[int(word)] for word in labels[i, :lens[i]]])\n",
    "\n",
    "            batch_preds_acc.extend(predicted[i, :lens[i]].cpu().numpy())  # Append predictions but only up to the actual length of the sentence\n",
    "            batch_labels_acc.extend(labels[i, :lens[i]].cpu().numpy())\n",
    "\n",
    "\n",
    "\n",
    "        correct += sum(p == l for p, l in zip(batch_preds_acc, batch_labels_acc))  # Accumulate correct predictions for this batch\n",
    "        total_words += sum(lens)  # Accumulate the actual sentence lengths for this batch\n",
    "\n",
    "        all_batch_preds.extend(batch_preds)  # Append batch predictions to the list\n",
    "        all_batch_labels.extend(batch_labels)  # Append batch labels to the list\n",
    "\n",
    "accuracy = 100 * correct / total_words\n",
    "f1 = f1_score(all_batch_labels, all_batch_preds,average='macro')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5YsvMrlSt_N8",
    "outputId": "e8d097ef-2881-45b9-b828-a3fbd9de5a61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  94.36%, F1 Score:  0.73\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy: {accuracy: .2f}%, F1 Score: {f1: .2f}')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
